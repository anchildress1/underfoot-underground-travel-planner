# Underfoot Python Backend

<p align="center">
  <img src="../frontend/public/favicon.png" alt="Underfoot logo" width="100" height="100" />
</p>

> ğŸ Python backend for Underfoot Underground Travel Planner, built for Cloudflare Workers with FastAPI

Blazingly fast, secure, and observable Python backend featuring structured logging, dual-layer caching, and AI-powered search orchestration.

## âœ¨ Features

- ğŸš€ **Edge Performance**: Deployed on Cloudflare Workers for <100ms cold starts
- ğŸ”’ **Security First**: Input validation, rate limiting, XSS protection, secret management
- ğŸ“Š **Observability**: Structured JSON logging, request tracing, metrics collection
- ğŸ’¾ **Dual-Layer Caching**: KV (edge, <1ms) + Supabase (persistent, queryable)
- ğŸ¤– **AI Orchestration**: OpenAI for parsing and response generation
- ğŸŒ **Multi-Source Search**: SERP API, Reddit, Eventbrite integration
- âš¡ **Async Everything**: HTTPX for non-blocking I/O
- ğŸ¯ **Type Safety**: Pydantic v2 for validation (5-50x faster)

## ğŸ—ï¸ Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚         Cloudflare Workers (Python)          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Framework:      FastAPI (ASGI)              â”‚
â”‚ HTTP Client:    httpx (async)               â”‚
â”‚ OpenAI:         openai-python (official)    â”‚
â”‚ Cache:          KV + Supabase               â”‚
â”‚ Logging:        structlog (structured)      â”‚
â”‚ Security:       Pydantic validation         â”‚
â”‚ Testing:        pytest + pytest-asyncio     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸ“‹ Prerequisites

- Python 3.11+
- Poetry (dependency management)
- Cloudflare account (for deployment)
- API keys (OpenAI, SERP, Reddit, Eventbrite, Geoapify)
- Supabase project (for caching)

## ğŸš€ Quick Start

### 1. Install Dependencies

```bash
# Install project dependencies
cd backend-python
uv sync
```

### 2. Configure Environment

```bash
# Copy example environment file
cp .env.example .env

# Edit .env with your API keys
vim .env
```

"""Underfoot Python Backend

This README documents how to run and test the backend service.
"""

# Underfoot Python Backend

<p align="center">
  <img src="../frontend/public/favicon.png" alt="Underfoot logo" width="100" height="100" />
</p>

> ğŸ Python backend for Underfoot Underground Travel Planner, built for Cloudflare Workers with FastAPI

Blazingly fast, secure, and observable Python backend featuring structured logging, dual-layer caching, and AI-powered search orchestration.

## âœ¨ Features

- ğŸš€ **Edge Performance**: Deployed on Cloudflare Workers for <100ms cold starts
- ğŸ”’ **Security First**: Input validation, rate limiting, XSS protection, secret management
- ğŸ“Š **Observability**: Structured JSON logging, request tracing, metrics collection
- ğŸ’¾ **Dual-Layer Caching**: KV (edge, <1ms) + Supabase (persistent, queryable)
- ğŸ¤– **AI Orchestration**: OpenAI for parsing and response generation
- ğŸŒ **Multi-Source Search**: SERP API, Reddit, Eventbrite integration
- âš¡ **Async Everything**: HTTPX for non-blocking I/O
- ğŸ¯ **Type Safety**: Pydantic v2 for validation (5-50x faster)

## ğŸ—ï¸ Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚         Cloudflare Workers (Python)          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Framework:      FastAPI (ASGI)              â”‚
â”‚ HTTP Client:    httpx (async)               â”‚
â”‚ OpenAI:         openai-python (official)    â”‚
â”‚ Cache:          KV + Supabase               â”‚
â”‚ Logging:        structlog (structured)      â”‚
â”‚ Security:       Pydantic validation         â”‚
â”‚ Testing:        pytest + pytest-asyncio     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸ“‹ Prerequisites

- Python 3.11+
- Poetry (dependency management)
- Cloudflare account (for deployment)
- API keys (OpenAI, SERP, Reddit, Eventbrite, Geoapify)
- Supabase project (for caching)

## ğŸš€ Quick Start

### 1. Install Dependencies

```bash
# Install Poetry (if not installed)
# Install uv (if not installed)
curl -LsSf https://astral.sh/uv/install.sh | sh

# Install project dependencies
cd backend
uv sync
```

### 2. Configure Environment

```bash
# Copy example environment file
cp .env.example .env

# Edit .env with your API keys
vim .env
```

### 3. Run Locally

```bash
# Activate virtual environment
# No need for shell activation with uv run

# Run development server
uvicorn src.workers.chat_worker:app --reload --port 8000

# Or use wrangler for local development
wrangler dev
```

### 4. Test

```bash
# Run all tests with coverage
uv run pytest

# Run specific test file
uv run pytest tests/unit/test_services/test_openai_service.py

# Run with verbose output
uv run pytest -v

# Generate coverage report (HTML)
uv run pytest --cov=src --cov-report=html
```

## Run dev servers & tests (per-service)

Copy the appropriate `.env` files first (see `.env.example` in each service).

Front-end â€” dev server

```bash
cd frontend
npm install
npm run dev
```

Front-end â€” tests

```bash
cd frontend
npm install
npm test
# coverage report (frontend)
npm run test:coverage
```

Back-end â€” dev server

```bash
# Use the backend folder
cd backend
uv sync
uv run uvicorn src.workers.chat_worker:app --reload --port 8000
```

Back-end â€” tests

```bash
cd backend
uv sync
uv run pytest
# run with coverage
uv run pytest --cov=src --cov-report=term-missing
```

Run both locally (from repo root)

```bash
# Option A: root script (if defined)
### Structured Logging

# Option B: manually open two terminals
cd frontend && npm run dev
cd backend && uv run uvicorn src.workers.chat_worker:app --reload --port 8000
```

Notes

- Ensure `frontend/.env` and `backend/.env` are populated from their example files before starting.
- If VS Code can't resolve imports for the backend, select the Poetry interpreter in the Command Palette.

## ğŸ“¦ Project Structure

```
backend/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ workers/
â”‚   â”‚   â””â”€â”€ chat_worker.py           # Main FastAPI application
â”‚   â”œâ”€â”€ services/
â”‚   â”‚   â”œâ”€â”€ openai_service.py        # OpenAI integration
â”‚   â”‚   â”œâ”€â”€ geocoding_service.py     # Geoapify location normalization
â”‚   â”‚   â”œâ”€â”€ serp_service.py          # SERP API search
â”‚   â”‚   â”œâ”€â”€ reddit_service.py        # Reddit RSS integration
â”‚   â”‚   â”œâ”€â”€ eventbrite_service.py    # Eventbrite events
â”‚   â”‚   â”œâ”€â”€ scoring_service.py       # Result scoring & ranking
â”‚   â”‚   â”œâ”€â”€ cache_service.py         # Dual-layer caching
â”‚   â”‚   â””â”€â”€ search_service.py        # Search orchestration
â”‚   â”œâ”€â”€ models/
â”‚   â”‚   â”œâ”€â”€ request_models.py        # Pydantic request models
â”‚   â”‚   â”œâ”€â”€ response_models.py       # Pydantic response models
â”‚   â”‚   â””â”€â”€ domain_models.py         # Domain entities
â”‚   â”œâ”€â”€ middleware/
â”‚   â”‚   â”œâ”€â”€ tracing_middleware.py    # Request tracing
â”‚   â”‚   â”œâ”€â”€ cors_middleware.py       # CORS configuration
â”‚   â”‚   â””â”€â”€ security_middleware.py   # Security headers
â”‚   â”œâ”€â”€ utils/
â”‚   â”‚   â”œâ”€â”€ logger.py                # Structured logging
â”‚   â”‚   â”œâ”€â”€ errors.py                # Custom exceptions
â”‚   â”‚   â””â”€â”€ metrics.py               # Metrics collection
â”‚   â””â”€â”€ config/
â”‚       â”œâ”€â”€ settings.py              # Environment settings
â”‚       â””â”€â”€ constants.py             # Application constants
â”œâ”€â”€ tests/
â”‚   â”œâ”€â”€ unit/
â”‚   â”œâ”€â”€ integration/
â”‚   â””â”€â”€ e2e/
â”œâ”€â”€ pyproject.toml                   # Poetry dependencies
â”œâ”€â”€ wrangler.toml                    # Cloudflare Workers config
â”œâ”€â”€ .env.example                     # Environment template
â”œâ”€â”€ AGENTS.md                        # Development guidelines
â””â”€â”€ README.md                        # This file
```

## ğŸ”§ Configuration

### Environment Variables

Required environment variables (see `.env.example`):

```bash
# OpenAI
OPENAI_API_KEY=sk-...

# External APIs
GEOAPIFY_API_KEY=...
SERPAPI_KEY=...
REDDIT_CLIENT_ID=...
REDDIT_CLIENT_SECRET=...
EVENTBRITE_TOKEN=...

# Supabase
SUPABASE_URL=https://...
SUPABASE_KEY=...  # app_admin_user password

# Application
ENVIRONMENT=development
LOG_LEVEL=INFO
CACHE_TTL_SECONDS=60
```

### Cloudflare Secrets

Set production secrets using Wrangler:

```bash
wrangler secret put OPENAI_API_KEY
wrangler secret put GEOAPIFY_API_KEY
wrangler secret put SERPAPI_KEY
wrangler secret put REDDIT_CLIENT_ID
wrangler secret put REDDIT_CLIENT_SECRET
wrangler secret put EVENTBRITE_TOKEN
wrangler secret put SUPABASE_URL
wrangler secret put SUPABASE_KEY
```

## ğŸŒ API Endpoints

### Health Check

```bash
GET /health
```

Returns service health and dependency status.

### Search

```bash
POST /underfoot/search
Content-Type: application/json

{
  "chat_input": "hidden gems in Pikeville KY",
  "force": false
}
```

Returns AI-powered search results with location normalization and multi-source aggregation.

## ğŸš¢ Deployment

### Deploy to Cloudflare Workers

```bash
# Login to Cloudflare
wrangler login

# Deploy to production
wrangler deploy

# Deploy to specific environment
wrangler deploy --env production
```

All logs are JSON-formatted for easy parsing:

```json
{
  "event": "search.complete",
  "request_id": "search_abc123def456",
  "elapsed_ms": 1234,
  "result_count": 8,
  "primary_count": 5,
  "nearby_count": 3,
  "timestamp": "2025-01-02T10:30:00Z"
}
```

### Metrics

Cloudflare Analytics automatically tracks:
- Request count by endpoint
- Response time distribution (P50, P90, P95, P99)
- Error rate by type
- Cache hit/miss ratio

### Alerts

Configure alerts in Cloudflare dashboard:
- Error rate >1% (5min window)
- P95 latency >1s (5min window)
- Cache hit rate <70% (15min window)

## ğŸ§ª Testing

### Unit Tests

```bash
# Run all unit tests
uv run pytest tests/unit/

# Run with coverage
uv run pytest tests/unit/ --cov=src/services
```

### Integration Tests

```bash
# Run integration tests
uv run pytest tests/integration/
```

### End-to-End Tests

```bash
# Run e2e tests
uv run pytest tests/e2e/
```

## ğŸ”’ Security

- âœ… Input validation with Pydantic (XSS, injection prevention)
- âœ… Rate limiting (coming soon with KV-based sliding window)
- âœ… CORS strict allowlist
- âœ… Security headers (CSP, HSTS, X-Frame-Options)
- âœ… Secret management (environment variables + Cloudflare Secrets)
- âœ… Dependency vulnerability scanning (safety, bandit)

## ğŸ“ˆ Performance Targets

| Metric | Target | Current |
|--------|--------|---------|
| Cold Start | <100ms | TBD |
| Warm Response (chat) | <200ms | TBD |
| Warm Response (search) | <3s | TBD |
| Cache Hit Rate | >80% | TBD |
| P95 Latency | <500ms | TBD |
| Error Rate | <0.1% | TBD |

## ğŸ¤ Contributing

1. Follow the guidelines in `AGENTS.md`
2. Write tests for all new features
3. Ensure coverage >85%
4. Run linting: `uv run ruff check .`
5. Run type checking: `uv run mypy src/`
6. Format code: `uv run black .`

## ğŸ“„ License

See [LICENSE](../LICENSE) in the root directory.

---

**Built with â¤ï¸ using FastAPI, Cloudflare Workers, and Python 3.11+**

_This document was generated with Verdent AI assistance._
